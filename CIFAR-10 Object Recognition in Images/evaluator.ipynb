{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from datetime import datetime\n",
    "import math\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import model as cifar10\n",
    "import model2 as cifar10_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "tf.app.flags.DEFINE_string('eval_dir', '/Users/Furkan/Desktop/tmp/cifar10_eval', # tmp -> tmp2 for evaluation of model2\n",
    "                           \"\"\"Directory where to write event logs.\"\"\")\n",
    "tf.app.flags.DEFINE_string('eval_data', 'test',\n",
    "                           \"\"\"Either 'test' or 'train_eval'.\"\"\")\n",
    "tf.app.flags.DEFINE_string('checkpoint_dir', '/Users/Furkan/Desktop/tmp/cifar10_train', # tmp -> tmp2 for evaluation of model2\n",
    "                           \"\"\"Directory where to read model checkpoints.\"\"\")\n",
    "tf.app.flags.DEFINE_integer('eval_interval_secs', 60 * 5,\n",
    "                            \"\"\"How often to run the eval.\"\"\")\n",
    "tf.app.flags.DEFINE_integer('num_examples', 10000,\n",
    "                            \"\"\"Number of examples to run.\"\"\")\n",
    "tf.app.flags.DEFINE_boolean('run_once', True,\n",
    "                            \"\"\"Whether to run eval only once.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_once(saver, summary_writer, top_k_op, summary_op):\n",
    "    with tf.Session() as sess:\n",
    "        preds = []\n",
    "        ckpt = tf.train.get_checkpoint_state(FLAGS.checkpoint_dir)\n",
    "        if ckpt and ckpt.model_checkpoint_path:\n",
    "            saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "            global_step = ckpt.model_checkpoint_path.split('/')[-1].split('-')[-1]\n",
    "        else:\n",
    "            print('No checkpoint file found')\n",
    "            return\n",
    "\n",
    "        coord = tf.train.Coordinator()\n",
    "        try:\n",
    "            threads = []\n",
    "            for qr in tf.get_collection(tf.GraphKeys.QUEUE_RUNNERS):\n",
    "                threads.extend(qr.create_threads(sess, coord=coord, daemon=True,\n",
    "                                                 start=True))\n",
    "\n",
    "            num_iter = int(math.ceil(FLAGS.num_examples / FLAGS.batch_size))\n",
    "            true_count = 0\n",
    "            total_sample_count = num_iter * FLAGS.batch_size\n",
    "            step = 0\n",
    "\n",
    "            while step < num_iter and not coord.should_stop():\n",
    "                predictions = sess.run([top_k_op])\n",
    "                true_count += np.sum(predictions)\n",
    "                for i in range(len(predictions)):\n",
    "                    for j in range(len(predictions[i])):\n",
    "                        preds.append(predictions[i][j])\n",
    "                step += 1\n",
    "\n",
    "            total_parameters = 0\n",
    "            for variable in tf.trainable_variables():\n",
    "                # shape is an array of tf.Dimension\n",
    "                shape = variable.get_shape()\n",
    "                variable_parametes = 1\n",
    "                for dim in shape:\n",
    "                    variable_parametes *= dim.value\n",
    "                total_parameters += variable_parametes\n",
    "\n",
    "            print(\"%s: Total parameters @ 1 = %d\" % (datetime.now(), total_parameters))\n",
    "\n",
    "            precision = true_count / total_sample_count\n",
    "            print('%s: Total @ 1 = %d' % (datetime.now(), total_sample_count))\n",
    "            print('%s: Correct @ 1 = %d' % (datetime.now(), true_count))\n",
    "            print('%s: Wrong @ 1 = %d' % (datetime.now(), (total_sample_count - true_count)))\n",
    "            print('%s: Precision @ 1 = %.3f' % (datetime.now(), precision))\n",
    "\n",
    "            summary = tf.Summary()\n",
    "            summary.ParseFromString(sess.run(summary_op))\n",
    "            summary.value.add(tag='Precision @ 1', simple_value=precision)\n",
    "            summary_writer.add_summary(summary, global_step)\n",
    "\n",
    "        except Exception as e:\n",
    "            coord.request_stop(e)\n",
    "\n",
    "        coord.request_stop()\n",
    "        coord.join(threads, stop_grace_period_secs=10)\n",
    "\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path of network should be added as parameter for McNemar's Test\n",
    "# def evaluate(network, path):\n",
    "def evaluate(network): \n",
    "    with tf.Graph().as_default() as g:\n",
    "        eval_data = FLAGS.eval_data == 'test'\n",
    "\n",
    "        if network == 1:\n",
    "            images, labels = cifar10.inputs(eval_data=eval_data)\n",
    "            logits, w1, b1, w2, b2 = cifar10.create_model(images)\n",
    "        else:\n",
    "            images, labels = cifar10_2.inputs(eval_data=eval_data)\n",
    "            logits, w1, b1, w2, b2 = cifar10_2.create_model(images)\n",
    "\n",
    "        top_k_op = tf.nn.in_top_k(logits, labels, 1)\n",
    "\n",
    "        variable_averages = tf.train.ExponentialMovingAverage(\n",
    "            cifar10.MOVING_AVERAGE_DECAY)\n",
    "        variables_to_restore = variable_averages.variables_to_restore()\n",
    "        saver = tf.train.Saver(variables_to_restore)\n",
    "\n",
    "        summary_op = tf.summary.merge_all()\n",
    "\n",
    "        summary_writer = tf.summary.FileWriter(FLAGS.eval_dir, g)\n",
    "\n",
    "        while True:\n",
    "            eval_once(saver, summary_writer, top_k_op, summary_op)\n",
    "            if FLAGS.run_once:\n",
    "                break\n",
    "            time.sleep(FLAGS.eval_interval_secs)\n",
    "            \n",
    "    #return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_mcnemar_test(labels1, labels2):\n",
    "    pos_pos = pos_neg = neg_pos = neg_neg = 0\n",
    "\n",
    "    for idx, lab1 in enumerate(labels1):\n",
    "        lab2 = labels2[idx]\n",
    "\n",
    "        if lab2:\n",
    "            if lab1: pos_pos +=1\n",
    "            else: pos_neg +=1\n",
    "        else:\n",
    "            if not lab1: neg_neg +=1\n",
    "            else: neg_pos +=1\n",
    "\n",
    "    return np.asarray([[pos_pos, pos_neg],[neg_pos, neg_neg]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(argv=None):\n",
    "    cifar10.maybe_download_and_extract()\n",
    "    if tf.gfile.Exists(FLAGS.eval_dir):\n",
    "        tf.gfile.DeleteRecursively(FLAGS.eval_dir)\n",
    "    tf.gfile.MakeDirs(FLAGS.eval_dir)\n",
    "\n",
    "    evaluate(1) # Evaluate model 1\n",
    "    # evaluate(2) # Evaluate model 2, please change the flag of directory path tmp to tmp2, and comment out evaluate(1)\n",
    "\n",
    "    # evaluate() method had been implemented in a different way while applying McNemar's Test\n",
    "    # The method first implemented as returning label for network. Test has been applied.\n",
    "    # The test results can be shown on report with images.\n",
    "    \"\"\"mcnemar_test = apply_mcnemar_test(label_array1, label_array2)\n",
    "\n",
    "    print(\"\\n McNemar's Test: \\n\")\n",
    "    print(\"\\t Both correct: %s\" % str(mcnemar_test[0][0]))\n",
    "    print(\"\\t Both wrong: %s\" % str(mcnemar_test[1][1]))\n",
    "    print(\"\\t Only network-1 correct: %s\" % str(mcnemar_test[0][1]))\n",
    "    print(\"\\t Only network-2 correct: %s\" % str(mcnemar_test[1][0]))\"\"\"\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    tf.app.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
